# -*- mode: ruby -*-
# vi: set ft=ruby :

require 'rbconfig'

# üîç D√©tection IP r√©elle sur Windows
def detect_real_ip_windows
  output = `ipconfig`.force_encoding("IBM437").encode("UTF-8", invalid: :replace, undef: :replace, replace: '')
  lines = output.lines.map(&:strip)

  lines.each do |line|
    clean = line.encode('ASCII', invalid: :replace, undef: :replace, replace: '').gsub(/\s+/, ' ')
    if clean =~ /Adresse IPv4.*?: (\d+\.\d+\.\d+\.\d+)/
      ip = $1
      return ip if ip.start_with?('192.168.10.') || ip.start_with?('192.168.1.')
    end
  end

  nil
end

# üîç D√©tection IP sur Linux/macOS
def detect_real_ip_unix
  `ip route get 1.1.1.1`.match(/src (\d+\.\d+\.\d+\.\d+)/)&.captures&.first
end

# üîç D√©tection universelle
def detect_real_ip
  if RbConfig::CONFIG['host_os'] =~ /mswin|mingw|cygwin/
    detect_real_ip_windows
  else
    detect_real_ip_unix
  end
end

# üß† D√©duction du pr√©fixe r√©seau
def network_prefix
  ip = detect_real_ip
  return '192.168.10' if ip&.start_with?('192.168.10.')
  return '192.168.1'  if ip&.start_with?('192.168.1.')
  '192.168.10' # fallback
end

# üì¶ IPs dynamiques
server_ip = "#{network_prefix}.100"
load_balancer_range = "#{network_prefix}.150-#{network_prefix}.250"


# agents = { "agent1" => "#{network_prefix}.101",
#            "agent2" => "#{network_prefix}.102" }
# agents = { "agent1" => "#{network_prefix}.101"}
agents = {}
# Extra parameters in INSTALL_K3S_EXEC variable because of
# K3s picking up the wrong interface when starting server and agent
# https://github.com/alexellis/k3sup/issues/306

server_script = <<-SHELL
    sudo -i
    apk update
    apk add bash curl coreutils sudo openrc iproute2 e2fsprogs tcpdump wget tar
 
    if [ -f /usr/local/bin/k3s-uninstall.sh ]; then
      /usr/local/bin/k3s-uninstall.sh
    fi
    export INSTALL_K3S_EXEC="--bind-address=#{server_ip} --node-external-ip=#{server_ip} --flannel-iface=eth1"
    curl -sfL https://get.k3s.io | sh -
    while [ ! -f /var/lib/rancher/k3s/server/token ]; do
      echo "Sleeping for 2 seconds to wait for k3s to start"
      sleep 2
    done
    sudo chown vagrant:vagrant /etc/rancher/k3s/k3s.yaml
    echo 'export KUBECONFIG=/etc/rancher/k3s/k3s.yaml' >> /etc/profile
    
    sudo cp /var/lib/rancher/k3s/server/token /vagrant_shared
    sudo chmod +r /etc/rancher/k3s/k3s.yaml

    sudo cp /etc/rancher/k3s/k3s.yaml /vagrant_shared
    # petit alias 
    echo "alias k=kubectl" >> /home/vagrant/.bashrc
    echo 'if [ -f ~/.bashrc ]; then source ~/.bashrc; fi' >> /home/vagrant/.profile
    chown vagrant:vagrant /home/vagrant/.bashrc /home/vagrant/.profile
   
SHELL

agent_script = <<-SHELL
    sudo -i
    apk add curl
    if [ -f /usr/local/bin/k3s-agent-uninstall.sh ]; then
      /usr/local/bin/k3s-agent-uninstall.sh
    fi
    export K3S_TOKEN_FILE=/vagrant_shared/token
    export K3S_URL=https://#{server_ip}:6443
    export INSTALL_K3S_EXEC="--flannel-iface=eth1"
    curl -sfL https://get.k3s.io | sh -
    # r√©cup√©ration du token sur le serveur par scp

SHELL

Vagrant.configure("2") do |config|
  config.vm.box = "generic/alpine319"

  config.vm.define "server", primary: true do |server|
    server.vm.network "public_network", ip: server_ip
    
    server.vm.synced_folder "./shared", "/vagrant_shared"
    server.vm.hostname = "server"
    server.vm.provider "virtualbox" do |vb|
      vb.memory = "12000"
      vb.cpus = "2"
    end
    server.vm.provision "cluster-k3s", type: "shell", inline: server_script
    # server.vm.provision "taint",type: "shell", inline: <<-SHELL 
    # #!/bin/bash
    #   NODE_NAME="server"
    #   echo "‚è≥ Attente de la cr√©ation du n≈ìud '$NODE_NAME'..."
    #   # Boucle jusqu'√† ce que le n≈ìud apparaisse
    #   while true; do
    #     if kubectl get nodes | grep -w "$NODE_NAME" > /dev/null; then
    #       echo "‚úÖ N≈ìud '$NODE_NAME' d√©tect√©. Application du taint..."
    #       kubectl taint nodes "$NODE_NAME" node-role.kubernetes.io/master=true:NoSchedule
    #       break
    #     else
    #       sleep 2
    #     fi
    #   done
    # SHELL
    

    server.vm.provision "helm", type: "shell", inline: <<-SHELL
    #!/bin/bash
     # installation helm
    echo "installation helm"
    apk add git
    sudo curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
    chmod 700 get_helm.sh
    ./get_helm.sh
    SHELL

    server.vm.provision "metallb-install", type: "shell", inline: <<-SHELL
    # re creation du namespace vierge apr√®s suppression de son contenu
  echo "suppression de l'ancien package metallb-system"
	if kubectl get namespace metallb-system &> /dev/null; then
  		kubectl delete namespace metallb-system
	fi
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.8/config/manifests/metallb-native.yaml
# attente de cr√©ation des ressources dans metallb-system
echo "attente de cr√©ation des ressources dans metallb-system"
sleep 10
echo "attente que les pods soient ready"
kubectl wait --namespace metallb-system \
  --for=condition=Ready pod \
  --all --timeout=200s
kubectl get pods -n metallb-system -o wide
# configuration 
echo "configuration du loadBalancer"
kubectl -n metallb-system patch daemonset speaker \
  --type='json' \
  -p='[{"op": "remove", "path": "/spec/template/spec/nodeSelector/speaker"}]'|| true
echo "echelle des adresses : #{load_balancer_range}"


  kubectl apply -f - <<'EOF'
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: my-ip-pool
  namespace: metallb-system
spec:
  addresses:
  - #{load_balancer_range}

---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: l2-advertisement
  namespace: metallb-system
spec:
  ipAddressPools:
  - my-ip-pool
EOF
SHELL

server.vm.provision "jenkins", type: "shell", inline: <<-SHELL
echo "entree dans installation de jenkins"
if kubectl get namespace jenkins &> /dev/null; then
    kubectl delete namespace jenkins
fi

echo "=== Installation de Jenkins ==="
kubectl create namespace jenkins || true

# Volume persistant
mkdir -p /data/jenkins
echo "creation des volumes"
kubectl apply -f - <<EOF
apiVersion: v1
kind: PersistentVolume
metadata:
  name: jenkins-pv
  namespace: jenkins
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /data/jenkins
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: jenkins-pvc
  namespace: jenkins
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
EOF

echo " Pods + Service"
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: jenkins
  namespace: jenkins
spec:
  serviceName: "jenkins"
  replicas: 1
  selector:
    matchLabels:
      app: jenkins
  template:
    metadata:
      labels:
        app: jenkins
    spec:
      containers:
        - name: jenkins
          image: jenkins/jenkins:lts-jdk17
          ports:
            - name: http
              containerPort: 8080
            - name: agent
              containerPort: 50000
          volumeMounts:
            - name: jenkins-data
              mountPath: /var/jenkins_home
  volumeClaimTemplates:
    - metadata:
        name: jenkins-data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: jenkins
  namespace: jenkins
spec:
  type: LoadBalancer
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
      name: http
    - port: 50000
      targetPort: 50000
      protocol: TCP
      name: agent
  loadBalancerIP: #{network_prefix}.200
  selector:
    app: jenkins

EOF
echo "attente que le pod soit pret"
kubectl wait --for=condition=ready pod/jenkins-0 -n jenkins --timeout=200s
echo "‚úÖ Le pod est pr√™t, v√©rification de la disponibilit√© du mot de passe..."
# Boucle d‚Äôattente pour que Jenkins ait eu le temps de g√©n√©rer le mot de passe
for i in {1..30}; do
  if kubectl -n jenkins exec jenkins-0 -- test -f /var/jenkins_home/secrets/initialAdminPassword 2>/dev/null; then
    echo "üîë Fichier trouv√© ! R√©cup√©ration du mot de passe :"
    kubectl -n jenkins exec jenkins-0 -- cat /var/jenkins_home/secrets/initialAdminPassword
    break
  else
    echo "‚è≥ Fichier pas encore cr√©√©... tentative $i/30"
    sleep 10
  fi
done
  SHELL

server.vm.provision "backup-jenkins", type: "shell", inline: <<-SHELL
/vagrant_shared/backup-jenkins.sh
SHELL
server.vm.provision "restore-jenkins", type: "shell", inline: <<-SHELL
/vagrant_shared/restore-jenkins.sh
echo "attente que le pod soit pret"
kubectl wait --for=condition=ready pod/jenkins-0 -n jenkins --timeout=200s
echo "jenkins est pret"
SHELL

server.vm.provision "elk", type: "shell", inline: <<-SHELL

# installation d'elasticsearch en mode loadbalancer
  kubectl apply -f - <<'EOF'
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
spec:
  type: LoadBalancer
  selector:
    app: elasticsearch
  ports:
    - name: http
      port: 9200
      targetPort: 9200
  loadBalancerIP: #{network_prefix}.151
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: elasticsearch
spec:
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
        - name: elasticsearch
          image: docker.elastic.co/elasticsearch/elasticsearch:7.17.10
          ports:
            - containerPort: 9200
              name: http
          env:
            - name: discovery.type
              value: single-node
            - name: ES_JAVA_OPTS
              value: "-Xms256m -Xmx256m"
            - name: network.host
              value: "0.0.0.0"
            - name: bootstrap.memory_lock
              value: "false"
            - name: xpack.security.enabled
              value: "false"
          readinessProbe:
            httpGet:
              path: /
              port: 9200
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 3
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "250m"            
EOF
# installation kibana
  kubectl apply -f - <<'EOF'
apiVersion: v1
kind: Service
metadata:
  name: kibana
spec:
  type: LoadBalancer
  selector:
    app: kibana
  ports:
    - name: http
      port: 5601
      targetPort: 5601
  loadBalancerIP: #{network_prefix}.152
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
        - name: kibana
          image: docker.elastic.co/kibana/kibana:7.17.10
          ports:
            - containerPort: 5601
              name: http
          env:
            - name: ELASTICSEARCH_HOSTS
              value: "http://elasticsearch:9200"
            - name: SERVER_HOST
              value: "0.0.0.0"
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "250m"
EOF
  echo "attente que tous les pods soient prets"
kubectl wait  \
  --for=condition=Ready pod \
  --all --timeout=200s
SHELL


server.vm.provision "dashboard", type: "shell", inline: <<-SHELL

# initialisation si n√©cessaire
if kubectl get namespace kubernetes-dashboard &> /dev/null; then
        kubectl delete namespace kubernetes-dashboard
  fi
echo "installation dashboard"

helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
helm repo update

echo "creation namespace"
kubectl create namespace kubernetes-dashboard

helm install dashboard kubernetes-dashboard/kubernetes-dashboard \
  --namespace kubernetes-dashboard \
  --set kubernetesDashboard.service.type=LoadBalancer
echo "creation d'un compte admin"
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

kubectl apply -f - <<'EOF'
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
EOF

kubectl -n kubernetes-dashboard create token admin-user

echo "\n"
# des fois √ß√† marche pas il faut patcher
kubectl patch svc dashboard-kong-proxy -n kubernetes-dashboard \
  -p '{"spec": {"type": "LoadBalancer"}}'

echo "adresse du dashboard: "
IPDASH=$(kubectl get svc dashboard-kong-proxy -n kubernetes-dashboard \
  -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
echo "attente que tous les pods soient prets"
kubectl wait --namespace kubernetes-dashboard \
  --for=condition=Ready pod \
  --all --timeout=200s

echo "https://${IPDASH}"

SHELL

  end
  agents.each do |agent_name, agent_ip|
    config.vm.define agent_name do |agent|
      agent.vm.network "public_network", ip: agent_ip
      agent.vm.synced_folder "./shared", "/vagrant_shared"
      agent.vm.hostname = agent_name
      agent.vm.provider "virtualbox" do |vb|
        vb.memory = "8000"
        vb.cpus = "2"
      end
      agent.vm.provision "cluster-k3s", type: "shell", inline: agent_script
    end
  end
end
